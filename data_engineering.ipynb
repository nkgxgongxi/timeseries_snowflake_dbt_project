{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b97879c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark as snp\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark import types as T\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8202bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dags.snowpark_connection import snowpark_connect\n",
    "session, state_dict = snowpark_connect('./include/state.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "583a58ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict['load_stage_name']='LOAD_STAGE' \n",
    "state_dict['download_base_url']='https://s3.amazonaws.com/tripdata/'\n",
    "state_dict['trips_table_name']='TRIPS'\n",
    "state_dict['load_table_name'] = 'RAW_'\n",
    "\n",
    "import json\n",
    "with open('./include/state.json', 'w') as sdf:\n",
    "    json.dump(state_dict, sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edb1f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_database(session, state_dict:dict, prestaged=False):\n",
    "    _ = session.sql('CREATE OR REPLACE DATABASE '+state_dict['connection_parameters']['database']).collect()\n",
    "    _ = session.sql('CREATE SCHEMA '+state_dict['connection_parameters']['schema']).collect() \n",
    "\n",
    "    if prestaged:\n",
    "        sql_cmd = 'CREATE OR REPLACE STAGE '+state_dict['load_stage_name']+\\\n",
    "                  ' url='+state_dict['connection_parameters']['download_base_url']\n",
    "        _ = session.sql(sql_cmd).collect()\n",
    "    else: \n",
    "        _ = session.sql('CREATE STAGE IF NOT EXISTS '+state_dict['load_stage_name']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a0dd08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_database(session, state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434744b5",
   "metadata": {},
   "source": [
    "When I tried running the following code snippets, I faced error that files don't exist. Later, I figured that the file structures within S3 got updated. Data up to 2023 has been regrouped into yearly data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1c203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For files like 201306-citibike-tripdata.zip\n",
    "date_range1 = pd.period_range(start=datetime.strptime(\"201306\", \"%Y%m\"), \n",
    "                             end=datetime.strptime(\"201612\", \"%Y%m\"), \n",
    "                             freq='M').strftime(\"%Y%m\")\n",
    "file_name_end1 = '-citibike-tripdata.zip'\n",
    "files_to_download = [date+file_name_end1 for date in date_range1.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce42d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range2 = pd.period_range(start=datetime.strptime(\"201701\", \"%Y%m\"), \n",
    "                             end=datetime.strptime(\"202112\", \"%Y%m\"), \n",
    "                             freq='M').strftime(\"%Y%m\")\n",
    "file_name_end2 = '-citibike-tripdata.csv.zip'\n",
    "files_to_download = files_to_download + [date+file_name_end2 for date in date_range2.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b960b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['201306-citibike-tripdata.zip', '202005-citibike-tripdata.csv.zip']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_download = [files_to_download[i] for i in [0,102]]\n",
    "files_to_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ddde53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.use_warehouse(state_dict['compute_parameters']['fe_warehouse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96d6e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1_download_files = list()\n",
    "schema2_download_files = list()\n",
    "schema2_start_date = datetime.strptime('202102', \"%Y%m\")\n",
    "\n",
    "for file_name in files_to_download:\n",
    "    file_start_date = datetime.strptime(file_name.split(\"-\")[0], \"%Y%m\")\n",
    "    if file_start_date < schema2_start_date:\n",
    "        schema1_download_files.append(file_name)\n",
    "    else:\n",
    "        schema2_download_files.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88fa7537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['201306-citibike-tripdata.zip', '202005-citibike-tripdata.csv.zip'], [])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema1_download_files, schema2_download_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4005a2d",
   "metadata": {},
   "source": [
    "It seems like the source S3 has structure change, so the testing files presenter provided doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c187530",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1_download_files = ['202502-citibike-tripdata.zip']\n",
    "schema2_download_files = ['202503-citibike-tripdata.csv.zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ec70c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and unzipping: https://s3.amazonaws.com/tripdata/202502-citibike-tripdata.zip\n",
      "Putting 202502-citibike-tripdata_3.csv to stage: LOAD_STAGE/schema1/\n",
      "Downloading and unzipping: https://s3.amazonaws.com/tripdata/202503-citibike-tripdata.csv.zip\n",
      "Putting 202503-citibike-tripdata.csv to stage: LOAD_STAGE/schema2/\n"
     ]
    }
   ],
   "source": [
    "schema1_load_stage = state_dict['load_stage_name']+'/schema1/'\n",
    "schema2_load_stage = state_dict['load_stage_name']+'/schema2/'\n",
    "\n",
    "schema1_files_to_load = list()\n",
    "for zip_file_name in schema1_download_files:\n",
    "    \n",
    "    url = state_dict['download_base_url']+zip_file_name\n",
    "    \n",
    "    print('Downloading and unzipping: '+url)\n",
    "    r = requests.get(url)\n",
    "    file = ZipFile(BytesIO(r.content))\n",
    "    csv_file_name=file.namelist()[0]\n",
    "    file.extract(csv_file_name)\n",
    "    file.close()\n",
    "    \n",
    "    print('Putting '+csv_file_name+' to stage: '+schema1_load_stage)\n",
    "    session.file.put(local_file_name=csv_file_name, \n",
    "                     stage_location=schema1_load_stage, \n",
    "                     source_compression='NONE', \n",
    "                     overwrite=True)\n",
    "    schema1_files_to_load.append(csv_file_name)\n",
    "    os.remove(csv_file_name)\n",
    "    \n",
    "schema2_files_to_load = list()\n",
    "for zip_file_name in schema2_download_files:\n",
    "    \n",
    "    url = state_dict['download_base_url']+zip_file_name\n",
    "    \n",
    "    print('Downloading and unzipping: '+url)\n",
    "    r = requests.get(url)\n",
    "    file = ZipFile(BytesIO(r.content))\n",
    "    csv_file_name=file.namelist()[0]\n",
    "    file.extract(csv_file_name)\n",
    "    file.close()\n",
    "    \n",
    "    print('Putting '+csv_file_name+' to stage: '+schema2_load_stage)\n",
    "    session.file.put(local_file_name=csv_file_name, \n",
    "                     stage_location=schema2_load_stage, \n",
    "                     source_compression='NONE', \n",
    "                     overwrite=True)\n",
    "    schema2_files_to_load.append(csv_file_name)\n",
    "    os.remove(csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "270f65d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='load_stage/schema1/202502-citibike-tripdata_3.csv.gz', size=1218176, md5='ba700f6ccef6e67134de7c440a2797b3', last_modified='Sat, 26 Apr 2025 06:16:21 GMT'),\n",
       " Row(name='load_stage/schema2/202503-citibike-tripdata.csv.gz', size=123891344, md5='66aa886404ebada6e88653433838b655', last_modified='Sat, 26 Apr 2025 06:17:39 GMT')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "session.sql(\"list @\"+state_dict['load_stage_name']+\" pattern='.*20.*[.]gz'\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c7e3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting in February 2021 the schema changed\n",
    "load_schema = T.StructType([T.StructField(\"ride_id\", T.StringType()), \n",
    "                             T.StructField(\"rideable_type\", T.StringType()), \n",
    "                             T.StructField(\"STARTTIME\", T.StringType()), \n",
    "                             T.StructField(\"STOPTIME\", T.StringType()), \n",
    "                             T.StructField(\"START_STATION_NAME\", T.StringType()), \n",
    "                             T.StructField(\"START_STATION_ID\", T.StringType()),\n",
    "                             T.StructField(\"END_STATION_NAME\", T.StringType()), \n",
    "                             T.StructField(\"END_STATION_ID\", T.StringType()),\n",
    "                             T.StructField(\"START_STATION_LATITUDE\", T.StringType()),\n",
    "                             T.StructField(\"START_STATION_LONGITUDE\", T.StringType()),\n",
    "                             T.StructField(\"END_STATION_LATITUDE\", T.StringType()),\n",
    "                             T.StructField(\"END_STATION_LONGITUDE\", T.StringType()),\n",
    "                             T.StructField(\"USERTYPE\", T.StringType())])\n",
    "\n",
    "trips_table_schema = T.StructType([T.StructField(\"STARTTIME\", T.StringType()), \n",
    "                             T.StructField(\"STOPTIME\", T.StringType()), \n",
    "                             T.StructField(\"START_STATION_NAME\", T.StringType()), \n",
    "                             T.StructField(\"START_STATION_ID\", T.StringType()),\n",
    "                             T.StructField(\"END_STATION_NAME\", T.StringType()), \n",
    "                             T.StructField(\"END_STATION_ID\", T.StringType()),\n",
    "                             T.StructField(\"START_STATION_LATITUDE\", T.StringType()),\n",
    "                             T.StructField(\"START_STATION_LONGITUDE\", T.StringType()),\n",
    "                             T.StructField(\"END_STATION_LATITUDE\", T.StringType()),\n",
    "                             T.StructField(\"END_STATION_LONGITUDE\", T.StringType()),\n",
    "                             T.StructField(\"USERTYPE\", T.StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5290256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in ['schema1', 'schema2']:\n",
    "    session.create_dataframe([[None]*len(load_schema.names)], schema=load_schema)\\\n",
    "        .na.drop()\\\n",
    "        .write\\\n",
    "        .save_as_table(state_dict['load_table_name'] + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1bfdcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_format_options = {\"FIELD_OPTIONALLY_ENCLOSED_BY\": \"'\\\"'\", \"skip_header\": 1}\n",
    "load_stages = [schema1_load_stage, schema2_load_stage]\n",
    "table_name_suffix_ls = ['schema1', 'schema2']\n",
    "for i in range(2):\n",
    "    loaddf = session.read.option(\"SKIP_HEADER\", 1)\\\n",
    "                        .option(\"FIELD_OPTIONALLY_ENCLOSED_BY\", \"\\042\")\\\n",
    "                        .option(\"COMPRESSION\", \"GZIP\")\\\n",
    "                        .option(\"NULL_IF\", \"\\\\\\\\N\")\\\n",
    "                        .option(\"NULL_IF\", \"NULL\")\\\n",
    "                        .option(\"pattern\", \"'.*20.*[.]gz'\")\\\n",
    "                        .schema(load_schema)\\\n",
    "                        .csv('@'+load_stages[i])\\\n",
    "                        .copy_into_table(state_dict['load_table_name']+str(table_name_suffix_ls[i]), \n",
    "                                        format_type_options=csv_file_format_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysnowpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
